{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#writer pouya azizzadh from datrise"
      ],
      "metadata": {
        "id": "ATciaCNQUPgh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ByDxLluWhnYA",
        "outputId": "738791d6-b557-4359-c7e4-545fce090d2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MAWlA6r-K5yM",
        "outputId": "fa5fcbe4-a944-4b0c-92f2-bbec388d95cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rasterio in /usr/local/lib/python3.11/dist-packages (1.4.3)\n",
            "Requirement already satisfied: affine in /usr/local/lib/python3.11/dist-packages (from rasterio) (2.4.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.11/dist-packages (from rasterio) (25.3.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from rasterio) (2025.1.31)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.11/dist-packages (from rasterio) (8.1.8)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.11/dist-packages (from rasterio) (0.7.2)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.11/dist-packages (from rasterio) (2.0.2)\n",
            "Requirement already satisfied: click-plugins in /usr/local/lib/python3.11/dist-packages (from rasterio) (1.1.1)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from rasterio) (3.2.1)\n",
            "Requirement already satisfied: geopandas in /usr/local/lib/python3.11/dist-packages (1.0.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.11/dist-packages (from geopandas) (2.0.2)\n",
            "Requirement already satisfied: pyogrio>=0.7.2 in /usr/local/lib/python3.11/dist-packages (from geopandas) (0.10.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from geopandas) (24.2)\n",
            "Requirement already satisfied: pandas>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from geopandas) (2.2.2)\n",
            "Requirement already satisfied: pyproj>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from geopandas) (3.7.1)\n",
            "Requirement already satisfied: shapely>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from geopandas) (2.0.7)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.4.0->geopandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.4.0->geopandas) (2025.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from pyogrio>=0.7.2->geopandas) (2025.1.31)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: pywavelets in /usr/local/lib/python3.11/dist-packages (1.8.0)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from pywavelets) (2.0.2)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (3.1.5)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl) (2.0.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install rasterio\n",
        "!pip install geopandas matplotlib\n",
        "!pip install pywavelets\n",
        "!pip install openpyxl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vha24dr-GF3P"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import os\n",
        "import geopandas as gpd\n",
        "import rasterio\n",
        "from rasterio.features import geometry_mask\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import ListedColormap\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FR-xdGIb2SFf"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "file_path = \"/content/drive/MyDrive/spi(1981- 2024).xlsx\"\n",
        "\n",
        "data = pd.read_excel(file_path)\n",
        "\n",
        "regions = data['stcode'].unique()\n",
        "\n",
        "dataframes = []\n",
        "\n",
        "for region in regions:\n",
        "    region_data = data[data['stcode'] == region]\n",
        "\n",
        "    dataframes.append(region_data[[\"SPI12\",\"SPEI12\",\"tavg-monthy\",\"thorn-monthy\", \"p-pet-monthy\"]])\n",
        "\n",
        "conditional_dataset = np.mean(dataframes, axis=0)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "id": "5T1BIQJBG2RC",
        "outputId": "bc1589cd-f9e6-4261-f863-8d1df7f85891"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   stcode  year  month       p-pet    SPEI12           p     SPI12  \\\n",
              "0   40706  1981      1 -502.697569  0.224685  273.086626  0.201716   \n",
              "1   40706  1981      2 -510.886024  0.146129  268.229593  0.141658   \n",
              "2   40706  1981      3 -506.247172  0.196094  279.223805  0.277859   \n",
              "3   40706  1981      4 -417.424279  0.803169  356.383936  1.052638   \n",
              "4   40706  1981      5 -343.759258  1.249635  411.037469  1.609581   \n",
              "\n",
              "     p-monthy  tavg-monthy  thorn-monthy  p-pet-monthy  \n",
              "0   32.921828    -0.197978      0.000000     32.921828  \n",
              "1   21.039823     2.676500      3.452688     17.587135  \n",
              "2   47.530458     7.369631     19.462662     28.067796  \n",
              "3  116.055473     9.642099     31.447074     84.608399  \n",
              "4   77.991363    14.775899     67.248563     10.742800  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-401f5abe-8245-4b9d-b1c4-f9af20c305be\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>stcode</th>\n",
              "      <th>year</th>\n",
              "      <th>month</th>\n",
              "      <th>p-pet</th>\n",
              "      <th>SPEI12</th>\n",
              "      <th>p</th>\n",
              "      <th>SPI12</th>\n",
              "      <th>p-monthy</th>\n",
              "      <th>tavg-monthy</th>\n",
              "      <th>thorn-monthy</th>\n",
              "      <th>p-pet-monthy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>40706</td>\n",
              "      <td>1981</td>\n",
              "      <td>1</td>\n",
              "      <td>-502.697569</td>\n",
              "      <td>0.224685</td>\n",
              "      <td>273.086626</td>\n",
              "      <td>0.201716</td>\n",
              "      <td>32.921828</td>\n",
              "      <td>-0.197978</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>32.921828</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>40706</td>\n",
              "      <td>1981</td>\n",
              "      <td>2</td>\n",
              "      <td>-510.886024</td>\n",
              "      <td>0.146129</td>\n",
              "      <td>268.229593</td>\n",
              "      <td>0.141658</td>\n",
              "      <td>21.039823</td>\n",
              "      <td>2.676500</td>\n",
              "      <td>3.452688</td>\n",
              "      <td>17.587135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>40706</td>\n",
              "      <td>1981</td>\n",
              "      <td>3</td>\n",
              "      <td>-506.247172</td>\n",
              "      <td>0.196094</td>\n",
              "      <td>279.223805</td>\n",
              "      <td>0.277859</td>\n",
              "      <td>47.530458</td>\n",
              "      <td>7.369631</td>\n",
              "      <td>19.462662</td>\n",
              "      <td>28.067796</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>40706</td>\n",
              "      <td>1981</td>\n",
              "      <td>4</td>\n",
              "      <td>-417.424279</td>\n",
              "      <td>0.803169</td>\n",
              "      <td>356.383936</td>\n",
              "      <td>1.052638</td>\n",
              "      <td>116.055473</td>\n",
              "      <td>9.642099</td>\n",
              "      <td>31.447074</td>\n",
              "      <td>84.608399</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>40706</td>\n",
              "      <td>1981</td>\n",
              "      <td>5</td>\n",
              "      <td>-343.759258</td>\n",
              "      <td>1.249635</td>\n",
              "      <td>411.037469</td>\n",
              "      <td>1.609581</td>\n",
              "      <td>77.991363</td>\n",
              "      <td>14.775899</td>\n",
              "      <td>67.248563</td>\n",
              "      <td>10.742800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-401f5abe-8245-4b9d-b1c4-f9af20c305be')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-401f5abe-8245-4b9d-b1c4-f9af20c305be button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-401f5abe-8245-4b9d-b1c4-f9af20c305be');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9b5b4120-67ea-4399-98df-a11890a6efc9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9b5b4120-67ea-4399-98df-a11890a6efc9')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9b5b4120-67ea-4399-98df-a11890a6efc9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 7875,\n  \"fields\": [\n    {\n      \"column\": \"stcode\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 23,\n        \"min\": 40706,\n        \"max\": 40795,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          40751,\n          40754,\n          40706\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"year\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12,\n        \"min\": 1981,\n        \"max\": 2024,\n        \"num_unique_values\": 44,\n        \"samples\": [\n          2018,\n          2005,\n          2006\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"month\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 1,\n        \"max\": 12,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          11,\n          10,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"p-pet\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 608.2022868365686,\n        \"min\": -2290.0583533598915,\n        \"max\": 3118.1706980618865,\n        \"num_unique_values\": 7875,\n        \"samples\": [\n          -681.4547226394169,\n          -715.0589073363482,\n          -419.3009279099905\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SPEI12\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.997908610088276,\n        \"min\": -5.204912100220889,\n        \"max\": 3.984715827822286,\n        \"num_unique_values\": 7875,\n        \"samples\": [\n          -3.6790013182271397,\n          -2.555634248826227,\n          -0.5217770390870488\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"p\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 476.9328964913697,\n        \"min\": 20.594115200243138,\n        \"max\": 3992.6514191906713,\n        \"num_unique_values\": 7391,\n        \"samples\": [\n          287.4664966883913,\n          307.78394000518415,\n          1623.3302245541463\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SPI12\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9861932636817716,\n        \"min\": -5.075475550099187,\n        \"max\": 3.663600267618463,\n        \"num_unique_values\": 7875,\n        \"samples\": [\n          -3.1149533138893193,\n          -2.1312822113307144,\n          -1.004102198375424\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"p-monthy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 69.6980690283902,\n        \"min\": 0.0,\n        \"max\": 1032.46245964429,\n        \"num_unique_values\": 6947,\n        \"samples\": [\n          32.2097403663084,\n          4.69116743461861,\n          0.153303340770795\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tavg-monthy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9.60253538370596,\n        \"min\": -10.7768469305407,\n        \"max\": 38.4193685461218,\n        \"num_unique_values\": 7875,\n        \"samples\": [\n          25.6881657939487,\n          3.57323197265193,\n          9.38988418016256\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"thorn-monthy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 79.03652537962711,\n        \"min\": 0.0,\n        \"max\": 544.138687457007,\n        \"num_unique_values\": 7515,\n        \"samples\": [\n          167.162589050912,\n          7.97356540658421,\n          150.285120891635\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"p-pet-monthy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 118.39516179712756,\n        \"min\": -544.138687457007,\n        \"max\": 908.072371172417,\n        \"num_unique_values\": 7873,\n        \"samples\": [\n          -131.274419594369,\n          -3.7633767982008,\n          -100.344243554057\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1k0GzRuvVo-X"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import rasterio\n",
        "import rasterio.warp\n",
        "import geopandas as gpd\n",
        "import torch\n",
        "# بارگذاری تصاویر TIFF\n",
        "\n",
        "tiff_folder = \"/content/drive/MyDrive/1981-2024-IMG\"\n",
        "spi_data = []\n",
        "for filename in sorted(os.listdir(tiff_folder)):\n",
        "    if filename.endswith('.tif') or filename.endswith('.tiff'):\n",
        "        with rasterio.open(os.path.join(tiff_folder, filename)) as src:\n",
        "            img = src.read(1)\n",
        "            if img.shape != (200, 200):\n",
        "                dst_transform = rasterio.transform.from_bounds(*src.bounds, width=200, height=200)\n",
        "                destination = np.zeros((200, 200), dtype=img.dtype)\n",
        "                rasterio.warp.reproject(\n",
        "                    source=img,\n",
        "                    destination=destination,\n",
        "                    src_transform=src.transform,\n",
        "                    src_crs=src.crs,\n",
        "                    dst_transform=dst_transform,\n",
        "                    dst_crs=src.crs,\n",
        "                    resampling=rasterio.warp.Resampling.bilinear\n",
        "                )\n",
        "                img = destination\n",
        "            spi_data.append(img)\n",
        "\n",
        "spi_data = np.nan_to_num(np.array(spi_data), nan=np.nanmean(spi_data))\n",
        "\n",
        "spi_data = torch.tensor(spi_data, dtype=torch.float32).unsqueeze(1).to(device)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OFqcl3BoeWpP"
      },
      "outputs": [],
      "source": [
        "condition_length =7\n",
        "num_features = conditional_dataset.shape[1]\n",
        "conditions = []\n",
        "for i in range(len(spi_data) - condition_length):\n",
        "    cond = pd.DataFrame(conditional_dataset[i:i + condition_length]).values\n",
        "    cond = cond.reshape(1, condition_length, num_features)\n",
        "    conditions.append(cond)\n",
        "\n",
        "conditions = torch.tensor(np.concatenate(conditions, axis=0), dtype=torch.float32).to(device)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N7zg8G81omtb"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "assert len(spi_data) == len(conditions) + condition_length, \"تعداد تصاویر و شرط‌ها باید تطابق داشته باشد\"\n",
        "spi_data = spi_data[condition_length:]  # برش تصاویر برای تطبیق\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0zsEW4GtZJoe"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "spi_data_np = spi_data.cpu().numpy()\n",
        "conditions_np = conditions.cpu().numpy()\n",
        "\n",
        "# تقسیم داده‌ها به train و test\n",
        "spi_train, spi_test, cond_train, cond_test = train_test_split(\n",
        "    spi_data_np, conditions_np, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "spi_train = torch.tensor(spi_train, dtype=torch.float32).to(device)\n",
        "spi_test = torch.tensor(spi_test, dtype=torch.float32).to(device)\n",
        "cond_train = torch.tensor(cond_train, dtype=torch.float32).to(device)\n",
        "cond_test = torch.tensor(cond_test, dtype=torch.float32).to(device)\n",
        "\n",
        "train_dataset = TensorDataset(spi_train, cond_train)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "\n",
        "from torch.utils.data import SubsetRandomSampler, DataLoader\n",
        "dataset_size = len(train_dataset)\n",
        "indices = list(range(dataset_size))\n",
        "split = int(0.2 * dataset_size)  # 20% برای اعتبارسنجی\n",
        "train_indices, val_indices = indices[split:], indices[:split]\n",
        "train_sampler = SubsetRandomSampler(train_indices)\n",
        "val_sampler = SubsetRandomSampler(val_indices)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=8, sampler=train_sampler)\n",
        "val_dataloader = DataLoader(train_dataset, batch_size=8, sampler=val_sampler)\n",
        "\n",
        "\n",
        "test_dataset = TensorDataset(spi_test, cond_test)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sFl-VXHL3yHv"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, latent_dim=100, condition_dim=4, image_shape=(1, 200, 200)):\n",
        "        super(Generator, self).__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.condition_dim = condition_dim\n",
        "        self.image_shape = image_shape\n",
        "\n",
        "        self.fc1 = nn.Linear(latent_dim + condition_length * num_features, 512) s\n",
        "        self.fc2 = nn.Linear(512, 128 * 25 * 25)\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.ConvTranspose2d(128, 64, 4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.ConvTranspose2d(64, 32, 4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.ConvTranspose2d(32, 1, 4, stride=2, padding=1),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, z, condition):\n",
        "        condition = condition.view(condition.size(0), -1)\n",
        "        input = torch.cat([z, condition], dim=1)\n",
        "        x = self.fc1(input)\n",
        "        x = nn.LeakyReLU(0.2)(x)\n",
        "        x = self.fc2(x)\n",
        "        x = x.view(-1, 128, 25, 25)\n",
        "        img = self.model(x)\n",
        "        return img\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, image_shape=(1, 200, 200), condition_dim=4):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.condition_dim = condition_dim\n",
        "\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(1 + 1, 64, 4, stride=2, padding=1),  # +1 for condition channel\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Conv2d(64, 128, 4, stride=2, padding=1),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Conv2d(128, 256, 4, stride=2, padding=1),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Dropout(0.3)\n",
        "        )\n",
        "\n",
        "        dummy_input = torch.randn(1, 2, image_shape[1], image_shape[2])\n",
        "        dummy_output = self.conv(dummy_input)\n",
        "        linear_input_size = dummy_output.view(1, -1).shape[1]\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(linear_input_size, 1),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, img, condition):\n",
        "        cond_channel = condition[:, :, 0].unsqueeze(1).unsqueeze(2)\n",
        "\n",
        "        cond_channel = cond_channel.repeat(1, 1, img.shape[2], img.shape[3])\n",
        "        cond_channel = torch.nn.functional.interpolate(cond_channel, size=(img.shape[2], img.shape[3]), mode='bilinear', align_corners=False)\n",
        "\n",
        "        input_data = torch.cat([img, cond_channel], dim=1)\n",
        "\n",
        "        x = self.conv(input_data)\n",
        "\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        validity = self.fc(x)\n",
        "\n",
        "        return validity\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "import cv2\n",
        "import numpy.ma as ma\n",
        "\n",
        "mask_path = '/content/drive/MyDrive/iran.jpg'\n",
        "mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "mask = cv2.resize(mask, (200, 200), interpolation=cv2.INTER_NEAREST)\n",
        "mask = mask / 255.0\n",
        "mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "mask = cv2.resize(mask, (200, 200), interpolation=cv2.INTER_NEAREST)\n",
        "mask = mask / 255.0\n",
        "mask_resized = cv2.resize(mask, (200, 200), interpolation=cv2.INTER_NEAREST)"
      ],
      "metadata": {
        "id": "zm-OcXsiSbs0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjYDEpBETRxP",
        "outputId": "b416fc45-af60-436b-e053-4484898adbab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [0/50] | D Loss: 1.1554 | G Loss: 20.2704 | Val Loss: 1.8698 | Val R²: 0.3214\n",
            "Epoch [1/50] | D Loss: 1.2458 | G Loss: 23.5158 | Val Loss: 1.7409 | Val R²: 0.3291\n",
            "Epoch [2/50] | D Loss: 1.2423 | G Loss: 34.5427 | Val Loss: 1.7364 | Val R²: 0.3335\n",
            "Epoch [3/50] | D Loss: 1.1498 | G Loss: 36.0659 | Val Loss: 1.7555 | Val R²: 0.3273\n",
            "Epoch [4/50] | D Loss: 1.1954 | G Loss: 14.6820 | Val Loss: 1.7571 | Val R²: 0.3287\n",
            "Epoch [5/50] | D Loss: 1.0976 | G Loss: 13.0769 | Val Loss: 1.8180 | Val R²: 0.3309\n",
            "Epoch [6/50] | D Loss: 1.2419 | G Loss: 14.8003 | Val Loss: 1.7426 | Val R²: 0.3384\n",
            "Epoch [7/50] | D Loss: 1.0986 | G Loss: 23.2786 | Val Loss: 1.7805 | Val R²: 0.3380\n",
            "Epoch [8/50] | D Loss: 1.0983 | G Loss: 17.3913 | Val Loss: 1.6760 | Val R²: 0.3413\n",
            "Epoch [9/50] | D Loss: 1.0979 | G Loss: 12.5595 | Val Loss: 1.7477 | Val R²: 0.3271\n",
            "Epoch [10/50] | D Loss: 1.0973 | G Loss: 30.9145 | Val Loss: 1.8200 | Val R²: 0.3301\n",
            "Epoch [11/50] | D Loss: 1.0983 | G Loss: 20.8362 | Val Loss: 1.6873 | Val R²: 0.3408\n",
            "Epoch [12/50] | D Loss: 1.1938 | G Loss: 20.4605 | Val Loss: 1.7314 | Val R²: 0.3402\n",
            "Epoch [13/50] | D Loss: 1.1459 | G Loss: 24.6928 | Val Loss: 1.8301 | Val R²: 0.3342\n",
            "Epoch [14/50] | D Loss: 1.1938 | G Loss: 13.2594 | Val Loss: 1.7386 | Val R²: 0.3413\n",
            "Epoch [15/50] | D Loss: 1.1937 | G Loss: 36.3741 | Val Loss: 1.7114 | Val R²: 0.3424\n",
            "Epoch [16/50] | D Loss: 1.0974 | G Loss: 13.9745 | Val Loss: 1.7800 | Val R²: 0.3402\n",
            "Epoch [17/50] | D Loss: 1.1455 | G Loss: 29.4826 | Val Loss: 1.6941 | Val R²: 0.3454\n",
            "Epoch [18/50] | D Loss: 1.2418 | G Loss: 36.6715 | Val Loss: 1.7897 | Val R²: 0.3446\n",
            "Epoch [19/50] | D Loss: 1.0975 | G Loss: 25.5998 | Val Loss: 1.7685 | Val R²: 0.3442\n",
            "Epoch [20/50] | D Loss: 1.1456 | G Loss: 32.9113 | Val Loss: 1.7728 | Val R²: 0.3395\n",
            "Epoch [21/50] | D Loss: 1.0493 | G Loss: 23.6022 | Val Loss: 1.6477 | Val R²: 0.3499\n",
            "Epoch [22/50] | D Loss: 1.1936 | G Loss: 27.4100 | Val Loss: 1.7054 | Val R²: 0.3418\n",
            "Epoch [23/50] | D Loss: 1.2418 | G Loss: 22.8741 | Val Loss: 1.7955 | Val R²: 0.3405\n",
            "Epoch [24/50] | D Loss: 1.0973 | G Loss: 15.4428 | Val Loss: 1.7844 | Val R²: 0.3360\n",
            "Epoch [25/50] | D Loss: 1.2418 | G Loss: 17.8785 | Val Loss: 1.7305 | Val R²: 0.3433\n",
            "Epoch [26/50] | D Loss: 1.0972 | G Loss: 17.5729 | Val Loss: 1.7399 | Val R²: 0.3419\n",
            "Epoch [27/50] | D Loss: 1.0973 | G Loss: 30.4922 | Val Loss: 1.7489 | Val R²: 0.3368\n",
            "Epoch [28/50] | D Loss: 1.2900 | G Loss: 21.1371 | Val Loss: 1.8058 | Val R²: 0.3424\n",
            "Epoch [29/50] | D Loss: 1.0973 | G Loss: 23.4030 | Val Loss: 1.6728 | Val R²: 0.3510\n",
            "Epoch [30/50] | D Loss: 1.2418 | G Loss: 30.0075 | Val Loss: 1.8161 | Val R²: 0.3310\n",
            "Epoch [31/50] | D Loss: 1.2900 | G Loss: 12.3433 | Val Loss: 1.7004 | Val R²: 0.3432\n",
            "Epoch [32/50] | D Loss: 1.1936 | G Loss: 34.1072 | Val Loss: 1.7262 | Val R²: 0.3357\n",
            "Epoch [33/50] | D Loss: 1.1936 | G Loss: 31.7432 | Val Loss: 1.7577 | Val R²: 0.3354\n",
            "Epoch [34/50] | D Loss: 1.1936 | G Loss: 23.4737 | Val Loss: 1.8183 | Val R²: 0.3364\n",
            "Epoch [35/50] | D Loss: 1.0973 | G Loss: 38.0930 | Val Loss: 1.6489 | Val R²: 0.3492\n",
            "Epoch [36/50] | D Loss: 1.0972 | G Loss: 25.1706 | Val Loss: 1.6712 | Val R²: 0.3487\n",
            "Epoch [37/50] | D Loss: 1.0972 | G Loss: 16.7209 | Val Loss: 1.7017 | Val R²: 0.3402\n",
            "Epoch [38/50] | D Loss: 1.0494 | G Loss: 23.3293 | Val Loss: 1.7737 | Val R²: 0.3334\n",
            "Epoch [39/50] | D Loss: 1.0975 | G Loss: 28.0555 | Val Loss: 1.6937 | Val R²: 0.3446\n",
            "Epoch [40/50] | D Loss: 1.0491 | G Loss: 14.7323 | Val Loss: 1.6849 | Val R²: 0.3434\n",
            "Epoch [41/50] | D Loss: 1.2420 | G Loss: 21.0116 | Val Loss: 1.7795 | Val R²: 0.3404\n",
            "Epoch [42/50] | D Loss: 1.1455 | G Loss: 17.4953 | Val Loss: 1.7246 | Val R²: 0.3396\n",
            "Epoch [43/50] | D Loss: 1.1936 | G Loss: 19.4709 | Val Loss: 1.7485 | Val R²: 0.3379\n",
            "Epoch [44/50] | D Loss: 1.1458 | G Loss: 33.7686 | Val Loss: 1.9188 | Val R²: 0.3335\n",
            "Epoch [45/50] | D Loss: 1.0492 | G Loss: 14.3474 | Val Loss: 1.7050 | Val R²: 0.3440\n",
            "Epoch [46/50] | D Loss: 1.2418 | G Loss: 29.2613 | Val Loss: 1.7684 | Val R²: 0.3379\n",
            "Epoch [47/50] | D Loss: 1.2899 | G Loss: 20.7834 | Val Loss: 1.7143 | Val R²: 0.3503\n",
            "Epoch [48/50] | D Loss: 1.1455 | G Loss: 32.5890 | Val Loss: 1.7923 | Val R²: 0.3391\n",
            "Epoch [49/50] | D Loss: 1.1937 | G Loss: 16.3441 | Val Loss: 1.7764 | Val R²: 0.3337\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# تعریف مدل‌ها\n",
        "latent_dim = 120\n",
        "condition_dim = 7\n",
        "generator = Generator(latent_dim, condition_dim).to(device)\n",
        "discriminator = Discriminator(condition_dim=condition_dim).to(device)\n",
        "num_epochs=50\n",
        "optimizer_G = torch.optim.Adam(generator.parameters(), lr=0.002, betas=(0.5, 0.999), weight_decay=1e-4)\n",
        "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=0.0001, betas=(0.5, 0.999), weight_decay=1e-4)\n",
        "\n",
        "adversarial_loss = nn.BCELoss()\n",
        "\n",
        "best_val_loss = 0\n",
        "counter = 0\n",
        "\n",
        "optimizer_G = torch.optim.Adam(generator.parameters(), lr=0.002, betas=(0.5, 0.999), weight_decay=1e-4)\n",
        "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=0.0001, betas=(0.5, 0.999), weight_decay=1e-4)\n",
        "scheduler_G = torch.optim.lr_scheduler.StepLR(optimizer_G, step_size=15, gamma=0.2)\n",
        "scheduler_D = torch.optim.lr_scheduler.StepLR(optimizer_D, step_size=15, gamma=0.2)\n",
        "\n",
        "lambda_mse = 15.0\n",
        "patience = 500\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (real_images, cond) in enumerate(train_dataloader):\n",
        "        batch_size = real_images.size(0)\n",
        "        real_images = real_images.to(device)\n",
        "        cond = cond.to(device)\n",
        "\n",
        "        optimizer_D.zero_grad()\n",
        "        real_validity = discriminator(real_images, cond)\n",
        "        real_loss = adversarial_loss(real_validity, torch.full((batch_size, 1), 0.8).to(device))\n",
        "        z = torch.randn(batch_size, latent_dim).to(device)\n",
        "        fake_images = generator(z, cond)\n",
        "\n",
        "        fake_validity = discriminator(fake_images.detach(), cond)\n",
        "        fake_loss = adversarial_loss(fake_validity, torch.full((batch_size, 1), 0.8).to(device))\n",
        "        d_loss = (real_loss + fake_loss)\n",
        "        d_loss.backward()\n",
        "        optimizer_D.step()\n",
        "\n",
        "        optimizer_G.zero_grad()\n",
        "        fake_validity = discriminator(fake_images, cond)\n",
        "        adv_loss = adversarial_loss(fake_validity, torch.ones(batch_size, 1).to(device))\n",
        "        mse_loss = torch.mean((real_images - fake_images) ** 2)\n",
        "        g_loss = adv_loss + lambda_mse * mse_loss\n",
        "        g_loss.backward()\n",
        "        optimizer_G.step()\n",
        "\n",
        "    scheduler_G.step()\n",
        "    scheduler_D.step()\n",
        "\n",
        "    val_g_loss = 0\n",
        "    val_r2 = []\n",
        "    with torch.no_grad():\n",
        "        for val_images, val_cond in val_dataloader:\n",
        "            val_images = val_images.to(device)\n",
        "            val_cond = val_cond.to(device)\n",
        "            z_val = torch.randn(val_images.size(0), latent_dim).to(device)\n",
        "            fake_val_images = generator(z_val, val_cond)\n",
        "            val_g_loss += torch.mean((val_images - fake_val_images) ** 2).item()\n",
        "            val_r2.append(r2_score(val_images.cpu().numpy().flatten(), fake_val_images.cpu().numpy().flatten()))\n",
        "    val_g_loss /= len(val_dataloader)\n",
        "    avg_val_r2 = np.mean(val_r2)\n",
        "\n",
        "    print(f\"Epoch [{epoch}/{num_epochs}] | D Loss: {d_loss.item():.4f} | G Loss: {g_loss.item():.4f} | Val Loss: {val_g_loss:.4f} | Val R²: {avg_val_r2:.4f}\")\n",
        "\n",
        "    if avg_val_r2 >= 0.39:\n",
        "        print(f\"R² به {avg_val_r2:.4f} رسید!\")\n",
        "        break\n",
        "\n",
        "    if val_g_loss < best_val_loss:\n",
        "        best_val_loss = val_g_loss\n",
        "        counter = 0\n",
        "        torch.save(generator.state_dict(), '/content/drive/MyDrive/best_generator.pth')\n",
        "    else:\n",
        "        counter += 1\n",
        "        if counter >= patience:\n",
        "            print(f\"Early Stopping در epoch {epoch} اعمال شد.\")\n",
        "            break\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TNGVF3rU7Gm9"
      },
      "outputs": [],
      "source": [
        "import pywt\n",
        "\n",
        "def wavelet_denoise(img, wavelet='db1', level=2, threshold=0.1):\n",
        "    \"\"\"\n",
        "    کاهش نویز تصویر با استفاده از Wavelet Transform\n",
        "    img: تصویر ورودی (numpy array)\n",
        "    wavelet: نوع موجک (مثلاً 'db1' برای Daubechies 1)\n",
        "    level: سطح تجزیه\n",
        "    threshold: آستانه برای حذف نویز\n",
        "    \"\"\"\n",
        "    coeffs = pywt.wavedec2(img, wavelet, level=level)\n",
        "    # Modify thresholding to keep the 3-tuple structure\n",
        "    coeffs = tuple([pywt.threshold(c, threshold, mode='soft') if isinstance(c, np.ndarray) else\n",
        "                   [pywt.threshold(sub_c, threshold, mode='soft') for sub_c in c]\n",
        "                   for c in coeffs])\n",
        "\n",
        "    denoised_img = pywt.waverec2(coeffs, wavelet)\n",
        "    return denoised_img\n",
        "\n",
        "def denoise_generated_images(generated_images):\n",
        "    generated_images = generated_images.detach().cpu().numpy().squeeze()  # Detach before converting to NumPy\n",
        "    denoised_images = np.zeros_like(generated_images)\n",
        "    for i in range(generated_images.shape[0]):\n",
        "        denoised_images[i] = wavelet_denoise(generated_images[i])\n",
        "    return torch.tensor(denoised_images, dtype=torch.float32).unsqueeze(1).to(device) # Convert back to tensor\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mFA0FVkZ72Br"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBIQuQmdwk5O",
        "outputId": "4b13a905-13f6-407f-d52f-15d70c078c69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "conds torch.Size([8, 7, 5])\n",
            "z torch.Size([8, 120])\n",
            "conds torch.Size([8, 7, 5])\n",
            "z torch.Size([8, 120])\n",
            "conds torch.Size([8, 7, 5])\n",
            "z torch.Size([8, 120])\n",
            "conds torch.Size([8, 7, 5])\n",
            "z torch.Size([8, 120])\n",
            "conds torch.Size([8, 7, 5])\n",
            "z torch.Size([8, 120])\n",
            "conds torch.Size([8, 7, 5])\n",
            "z torch.Size([8, 120])\n",
            "conds torch.Size([8, 7, 5])\n",
            "z torch.Size([8, 120])\n",
            "conds torch.Size([8, 7, 5])\n",
            "z torch.Size([8, 120])\n",
            "conds torch.Size([8, 7, 5])\n",
            "z torch.Size([8, 120])\n",
            "conds torch.Size([8, 7, 5])\n",
            "z torch.Size([8, 120])\n",
            "conds torch.Size([8, 7, 5])\n",
            "z torch.Size([8, 120])\n",
            "conds torch.Size([8, 7, 5])\n",
            "z torch.Size([8, 120])\n",
            "conds torch.Size([8, 7, 5])\n",
            "z torch.Size([8, 120])\n",
            "Average SSIM: 0.8533052002283242\n",
            "Average PSNR: 4.527991824240273\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "import numpy.ma as ma\n",
        "import cv2\n",
        "\n",
        "def evaluate_model(generator, test_dataloader, mask_path='/content/drive/MyDrive/iran.jpg'):\n",
        "    generator.eval()\n",
        "    ssim_scores = []\n",
        "    psnr_scores = []\n",
        "    r2_scores = []\n",
        "    rmse_scores = []\n",
        "    real_images = []\n",
        "    pred_images = []\n",
        "\n",
        "    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "    mask_resized = cv2.resize(mask, (200, 200), interpolation=cv2.INTER_NEAREST) / 255.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for real_imgs, conds in test_dataloader:\n",
        "            z = torch.randn(real_imgs.size(0), latent_dim).to(device)\n",
        "            gen_imgs = generator(z, conds)\n",
        "            gen_imgs_denoised = denoise_generated_images(gen_imgs)\n",
        "\n",
        "            real_imgs_np = real_imgs.cpu().numpy().squeeze()\n",
        "            gen_imgs_np = gen_imgs_denoised.cpu().numpy().squeeze()\n",
        "\n",
        "            real_imgs_np = np.clip(real_imgs_np, 0, 1)\n",
        "            gen_imgs_np = np.clip(gen_imgs_np, 0, 1)\n",
        "\n",
        "            for i in range(real_imgs_np.shape[0]):\n",
        "                real_masked = ma.masked_where(mask_resized == 0, real_imgs_np[i])\n",
        "                gen_masked = ma.masked_where(mask_resized == 0, gen_imgs_np[i])\n",
        "\n",
        "                ssim_score = ssim(real_masked.filled(0), gen_masked.filled(0), data_range=1)\n",
        "                ssim_scores.append(ssim_score)\n",
        "\n",
        "                psnr_score = psnr(real_masked.filled(0), gen_masked.filled(0), data_range=1)\n",
        "                psnr_scores.append(psnr_score)\n",
        "\n",
        "                real_flat = real_masked.filled(0).flatten()\n",
        "                gen_flat = gen_masked.filled(0).flatten()\n",
        "                r2_scores.append(r2_score(real_flat, gen_flat))\n",
        "                rmse_scores.append(np.sqrt(mean_squared_error(real_flat, gen_flat)))\n",
        "\n",
        "                real_images.append(real_masked.filled(0))\n",
        "                pred_images.append(gen_masked.filled(0))\n",
        "\n",
        "    print(f\"Average SSIM: {np.mean(ssim_scores):.4f}\")\n",
        "    print(f\"Average PSNR: {np.mean(psnr_scores):.2f} dB\")\n",
        "    print(f\"Average R²: {np.mean(r2_scores):.4f}\")\n",
        "    print(f\"Average RMSE: {np.mean(rmse_scores):.4f}\")\n",
        "\n",
        "    return real_images, pred_images\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import ListedColormap, Normalize\n",
        "import numpy.ma as ma\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "colors = ['brown', 'red', 'orange', 'yellow', 'green', 'blue']\n",
        "cmap = ListedColormap(colors)\n",
        "\n",
        "def save_colored_images(real_images, pred_images, mask, output_dir='/content/drive/MyDrive/test_spi_image'):\n",
        "    \"\"\"\n",
        "    تابع برای ذخیره تصاویر واقعی و تولیدی با رنگ‌آمیزی خاص و اعمال ماسک.\n",
        "\n",
        "    پارامترها:\n",
        "    - real_images: لیست یا آرایه‌ای از تصاویر واقعی\n",
        "    - pred_images: لیست یا آرایه‌ای از تصاویر تولیدی\n",
        "    - mask: آرایه ماسک با مقادیر 0 و 1\n",
        "    - output_dir: مسیر پوشه‌ای که تصاویر در آن ذخیره می‌شوند\n",
        "    \"\"\"\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    mask_resized = cv2.resize(mask, (200, 200), interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "    def process_and_save(img, idx, prefix):\n",
        "        img = img.reshape(200, 200)\n",
        "        img_min, img_max = img.min(), img.max()\n",
        "\n",
        "        masked_img = ma.masked_where(mask_resized == 0, img)\n",
        "\n",
        "        plt.figure(figsize=(5, 5))\n",
        "        plt.imshow(masked_img, cmap=cmap, norm=Normalize(vmin=img_min, vmax=img_max))\n",
        "        plt.axis(\"off\")\n",
        "        plt.colorbar()\n",
        "        plt.savefig(os.path.join(output_dir, f'{prefix}_colored_{idx}.png'), bbox_inches='tight')\n",
        "        plt.close()\n",
        "\n",
        "    for idx, img in enumerate(real_images):\n",
        "        process_and_save(img, idx, 'real')\n",
        "\n",
        "    for idx, img in enumerate(pred_images):\n",
        "        process_and_save(img, idx, 'pred')\n",
        "\n"
      ],
      "metadata": {
        "id": "NQOJeM9bAFiz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_colored_images(real_images, pred_images,mask)"
      ],
      "metadata": {
        "id": "Q7CvBm7JC-fJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import os\n",
        "import rasterio\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import ListedColormap, Normalize\n",
        "import numpy.ma as ma\n",
        "import cv2\n",
        "import os\n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import Normalize\n",
        "import matplotlib.cm as cm\n",
        "import rasterio\n",
        "from numpy import ma\n",
        "# تنظیم دستگاه\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# ۱. آماده‌سازی داده‌ها\n",
        "future_file_path = \"/content/drive/MyDrive/120_months.xlsx\"\n",
        "\n",
        "# historical_data = pd.read_excel(historical_file_path)\n",
        "future_data = pd.read_excel(future_file_path)\n",
        "\n",
        "# تعریف نام ستون‌ها\n",
        "columns = [\"SPI12\", \"SPEI12\", \"tavg-monthy\", \"thorn-monthy\", \"p-pet-monthy\"]\n",
        "\n",
        "# تبدیل numpy array به pandas DataFrame\n",
        "historical_data = pd.DataFrame(conditional_dataset, columns=columns)\n",
        "\n",
        "historical_data = historical_data[[\"SPI12\", \"SPEI12\", \"tavg-monthy\", \"thorn-monthy\", \"p-pet-monthy\"]]\n",
        "future_data = future_data[[\"SPI12\", \"SPEI12\", \"tavg-monthy\", \"thorn-monthy\", \"p-pet-monthy\"]]\n",
        "spi_values=future_data[\"SPI12\"].values\n",
        "full_data = pd.concat([historical_data, future_data], ignore_index=True)\n",
        "\n",
        "condition_length = 7\n",
        "num_features = 5\n",
        "conditions_future = []\n",
        "for t in range(1, 121):\n",
        "    start_idx = len(historical_data) - (condition_length - (t - 1))\n",
        "    end_idx = start_idx + condition_length\n",
        "    cond = full_data.iloc[start_idx:end_idx].values\n",
        "    conditions_future.append(cond)\n",
        "\n",
        "conditions_future = np.array(conditions_future)\n",
        "conditions_future = torch.tensor(conditions_future, dtype=torch.float32).to(device)\n",
        "\n",
        "# ۲. تعریف و بارگذاری مدل Generator\n",
        "latent_dim = 120\n",
        "condition_dim = 7\n",
        "# generator = Generator(latent_dim, condition_dim).to(device)  # فرض می‌کنیم Generator تعریف شده است\n",
        "# generator.load_state_dict(torch.load('/content/drive/MyDrive/best_generator.pth'))\n",
        "generator.eval()\n",
        "\n",
        "# ۳. تولید تصاویر\n",
        "z_future = torch.randn(120, latent_dim).to(device)\n",
        "with torch.no_grad():\n",
        "    generated_images_future = generator(z_future, conditions_future)\n",
        "\n",
        "# ۴. کاهش نویز (اختیاری)\n",
        "generated_images_future = denoise_generated_images(generated_images_future)  # فرض می‌کنیم تابع تعریف شده است\n",
        "\n",
        "# ۵. ذخیره تصاویر\n",
        "generated_images_np = generated_images_future.cpu().numpy().squeeze()\n",
        "output_folder = \"/content/drive/MyDrive/future_images\"\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "for i in range(120):\n",
        "    img = generated_images_np[i]\n",
        "    with rasterio.open(\n",
        "        os.path.join(output_folder, f\"future_month_{i+1}.tiff\"),\n",
        "        'w',\n",
        "        driver='GTiff',\n",
        "        height=200,\n",
        "        width=200,\n",
        "        count=1,\n",
        "        dtype=img.dtype,\n",
        "        crs='+proj=latlong',\n",
        "        transform=rasterio.transform.from_bounds(44, 24, 64, 40, 200, 200)\n",
        "    ) as dst:\n",
        "        dst.write(img, 1)\n",
        "\n",
        "print(\"تصاویر ۱۲۰ ماه آینده با موفقیت تولید و ذخیره شدند!\")\n",
        "\n",
        "# ۶. نمایش تصاویر\n",
        "# تعریف رنگ‌ها برای ListedColormap\n",
        "colors = ['brown', 'red', 'orange', 'yellow', 'green', 'blue']\n",
        "cmap = ListedColormap(colors)\n",
        "\n",
        "# مسیر ماسک\n",
        "mask_path = \"/content/drive/MyDrive/iran.jpg\"  # مسیر ماسک را با مسیر واقعی جایگزین کنید\n",
        "\n",
        "# بارگذاری و تغییر اندازه ماسک\n",
        "mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "mask_resized = cv2.resize(mask, (200, 200), interpolation=cv2.INTER_NEAREST)\n",
        "generated_images_np.shape\n",
        "\n",
        "def display_future_images(output_folder, mask_resized):\n",
        "    start_year = 2024\n",
        "    start_month = 9\n",
        "\n",
        "    # لیست تمام فایل‌های TIFF در پوشه خروجی\n",
        "    tiff_files = [f for f in os.listdir(output_folder) if f.endswith('.tiff')]\n",
        "\n",
        "    # اطمینان از مرتب‌سازی صحیح فایل‌ها\n",
        "    tiff_files.sort(key=lambda x: int(x.split('_')[2].split('.')[0]))\n",
        "\n",
        "    # حلقه بر روی فایل‌های ذخیره‌شده\n",
        "    for i, filename in enumerate(tiff_files):\n",
        "        # خواندن تصویر از فایل TIFF\n",
        "        with rasterio.open(os.path.join(output_folder, filename)) as src:\n",
        "            img = src.read(1)\n",
        "        img_normalized = (img - img_min) / (img_max - img_min) * (10 - (-5)) + (-5)\n",
        "\n",
        "        # اعمال ماسک\n",
        "        masked_img = ma.masked_where(mask_resized == 0, img)\n",
        "\n",
        "        # محاسبه تاریخ\n",
        "        total_month = (start_month - 1) + i\n",
        "        year = start_year + total_month // 12\n",
        "        month = (total_month % 12) + 1\n",
        "        date_str = f\"{year}_{month:02d}\"\n",
        "\n",
        "        # نمایش و ذخیره تصویر\n",
        "        fig, ax = plt.subplots(figsize=(5, 5))\n",
        "        im = ax.imshow(masked_img, cmap=cmap)\n",
        "        ax.set_title(f\"{date_str}_spi_{spi_values[i]}\")\n",
        "        cbar = fig.colorbar(im, ax=ax)\n",
        "        cbar.set_label(\"SPI Values\")\n",
        "\n",
        "        # ایجاد پوشه خروجی برای PNGها (اگر وجود ندارد)\n",
        "        png_output_folder = \"/content/drive/MyDrive/2024_10_to_234_9_spi_image\"\n",
        "        os.makedirs(png_output_folder, exist_ok=True)\n",
        "\n",
        "        # ذخیره تصویر به صورت PNG\n",
        "        output_filename = os.path.join(png_output_folder, f\"{date_str}_spi_image.png\")\n",
        "        plt.savefig(output_filename, bbox_inches='tight', dpi=150)\n",
        "        plt.close(fig)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fng43kw3lt6t",
        "outputId": "99d7c6ad-1170-4229-cabc-fa29e24e4394"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "تصاویر ۱۲۰ ماه آینده با موفقیت تولید و ذخیره شدند!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display_future_images(output_folder, mask_resized)"
      ],
      "metadata": {
        "id": "v_K9uweO15rS"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}